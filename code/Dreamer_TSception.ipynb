{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the PyDreamer dataset folder\n",
    "dataset_folder = 'D:\\\\Tutorial\\\\Amir Kair University\\\\Article_Masters\\\\1_SelfCode\\\\Python\\\\EEG_ACTNN-main\\\\PyDreamer'\n",
    "\n",
    "# Initialize an empty list to store stimuli data\n",
    "stimuli_data = []\n",
    "\n",
    "# Iterate over each subfolder (person1 to person23)\n",
    "for person_folder in os.listdir(dataset_folder):\n",
    "    if person_folder == 'GPT talk.txt' or person_folder == 'Info.txt':\n",
    "        continue    \n",
    "    person_path = os.path.join(dataset_folder, person_folder)\n",
    "    \n",
    "    # Read age, gender, and person ID data\n",
    "    with open(os.path.join(person_path, 'age.txt'), 'r') as f:\n",
    "        age = int(f.read().strip())\n",
    "    with open(os.path.join(person_path, 'gender.txt'), 'r') as f:\n",
    "        gender = f.read().strip()\n",
    "    person_id = int(person_folder.lstrip('person'))  # extract person ID from folder name\n",
    "    \n",
    "    # Iterate over stimuli EEG data\n",
    "    for clip_id in range(1, 19):\n",
    "        # Read stimuli EEG data\n",
    "        with open(os.path.join(person_path, f'stimuli_eeg{clip_id}.txt'), 'r') as f:\n",
    "            eeg_data = [list(map(float, row.strip().split('\\t')[1:])) for row in f.readlines()] # exclude the electrode names\n",
    "        \n",
    "        # Read emotion scores\n",
    "        with open(os.path.join(person_path, 'valence.txt'), 'r') as f:\n",
    "            valence = float(f.readline().strip().split('\\t')[clip_id - 1])\n",
    "        with open(os.path.join(person_path, 'arousal.txt'), 'r') as f:\n",
    "            arousal = float(f.readline().strip().split('\\t')[clip_id - 1])\n",
    "        with open(os.path.join(person_path, 'dominance.txt'), 'r') as f:\n",
    "            dominance = float(f.readline().strip().split('\\t')[clip_id - 1])\n",
    "        \n",
    "        # Create a dictionary to store the stimuli data for this clip\n",
    "        clip_data = {\n",
    "            'Person_ID': person_id,\n",
    "            'Clip_ID': clip_id,\n",
    "            'Age': age,\n",
    "            'Gender': gender,\n",
    "            'Valence': valence,\n",
    "            'Arousal': arousal,\n",
    "            'Dominance': dominance\n",
    "        }\n",
    "        \n",
    "        # Add EEG data to the dictionary\n",
    "        for count, electrode in enumerate(['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']):\n",
    "            # clip_data[electrode] = [sample[i] for sample in eeg_data]\n",
    "            clip_data[electrode] = eeg_data[count]\n",
    "\n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        stimuli_data.append(clip_data)\n",
    "        \n",
    "        break # remove later analysis\n",
    "\n",
    "    # remove for further using\n",
    "    break # So I only store one data \n",
    "\n",
    "\n",
    "# Create a DataFrame for stimuli data\n",
    "stimuli_df = pd.DataFrame(stimuli_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = stimuli_df.drop(['Person_ID','Clip_ID','Age','Gender','Valence','Arousal','Dominance'], axis=1)\n",
    "y_df = stimuli_df[['Valence','Arousal','Dominance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25472"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_df.values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4388.2051, 4375.8975, 4378.4614,  ..., 4371.2822, 4371.7949,\n",
       "           4386.6665],\n",
       "          [4102.5640, 4093.8462, 4091.2820,  ..., 4092.3076, 4089.7437,\n",
       "           4098.9741],\n",
       "          [4219.4873, 4252.8203, 4230.2563,  ..., 4237.4360, 4214.3589,\n",
       "           4175.8975],\n",
       "          ...,\n",
       "          [4454.3589, 4466.6665, 4461.0259,  ..., 4475.3848, 4466.1538,\n",
       "           4451.7949],\n",
       "          [4326.1538, 4372.8203, 4328.2051,  ..., 4377.9487, 4351.7949,\n",
       "           4302.5640],\n",
       "          [4165.1284, 4247.1797, 4203.5898,  ..., 4230.2563, 4206.6665,\n",
       "           4133.3335]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = torch.tensor(np.zeros((1,1,14,25472)))\n",
    "for i, item in enumerate(x_df.values[0]):\n",
    "    x_t[0,0,i,:] = torch.tensor(item)\n",
    "\n",
    "# len(x_df.values[0][1])\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import generate_TS_channel_order\n",
    "from networks import TSception\n",
    "\n",
    "#original_order = ['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2']   # DEAP is used as an example\n",
    "original_order = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6','F4', 'F8', 'AF4']\n",
    "\n",
    "TS_order = generate_TS_channel_order(original_order)   # generate proper channel orders for the asymmetric spatial layer in TSception\n",
    "\n",
    "#data = torch.randn(1, 1, 14, 512)   # (batch_size=1, cnn_channel=1, EEG_channel=14, data_points=25472)\n",
    "data = x_t\n",
    "data = data.float()  # Convert input tensor to float\n",
    "\n",
    "idx = []\n",
    "for chan in TS_order:\n",
    "    idx.append(original_order.index(chan))\n",
    "data = data[:, :, idx, :]    # (batch_size=1, cnn_channel=1, EEG_channel=14, data_points=25472) Some channels are not selected, hence EEG channel becomes 28.\n",
    "\n",
    "TS = TSception(\n",
    "    num_classes=3, \n",
    "    input_size=(1, 14, 25472),\n",
    "    sampling_rate=128, \n",
    "    num_T=15,   # num_T controls the number of temporal filters\n",
    "    num_S=15,   # num_S controls the size of hidden embedding due to the global average pooling. Please increase it if you need a larger model capacity, e.g., subject-independent case\n",
    "    hidden=32,   \n",
    "    dropout_rate=0.5\n",
    ")\n",
    "\n",
    "preds = TS(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1571,  0.2670, -0.0390]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import *\n",
    "from prepare_data_DEAP import *\n",
    "import argparse\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    ######## Data ########\n",
    "    parser.add_argument('--dataset', type=str, default='DEAP')\n",
    "    parser.add_argument('--data-path', type=str, default='/home/dingyi/data/deap/')\n",
    "    parser.add_argument('--subjects', type=int, default=32)\n",
    "    parser.add_argument('--num-class', type=int, default=2, choices=[2, 3, 4])\n",
    "    parser.add_argument('--label-type', type=str, default='A', choices=['A', 'V'])\n",
    "    parser.add_argument('--segment', type=int, default=4, help='segment length in seconds')\n",
    "    parser.add_argument('--trial-duration', type=int, default=60, help='trial duration in seconds')\n",
    "    parser.add_argument('--overlap', type=float, default=0)\n",
    "    parser.add_argument('--sampling-rate', type=int, default=128)\n",
    "    parser.add_argument('--input-shape', type=tuple, default=(1, 28, 512))\n",
    "    parser.add_argument('--data-format', type=str, default='raw')\n",
    "    ######## Training Process ########\n",
    "    parser.add_argument('--random-seed', type=int, default=2021)\n",
    "    parser.add_argument('--max-epoch', type=int, default=500)  \n",
    "    parser.add_argument('--batch-size', type=int, default=64)\n",
    "    parser.add_argument('--learning-rate', type=float, default=1e-3)\n",
    "    parser.add_argument('--dropout', type=float, default=0.5)\n",
    "\n",
    "    parser.add_argument('--save-path', default='./save/')\n",
    "    parser.add_argument('--load-path', default='./save/max-acc.pth')\n",
    "    parser.add_argument('--gpu', default='0')\n",
    "    parser.add_argument('--save-model', type=bool, default=True)\n",
    "    ######## Model Parameters ########\n",
    "    parser.add_argument('--model', type=str, default='TSception')\n",
    "    parser.add_argument('--T', type=int, default=15)\n",
    "    parser.add_argument('--graph-type', type=str, default='TS', choices=['TS', 'O'], \n",
    "                        help='TS for the channel order of TSception, O for the original channel order')\n",
    "    parser.add_argument('--hidden', type=int, default=32)\n",
    "\n",
    "    ######## Reproduce the result using the saved model ######\n",
    "    parser.add_argument('--reproduce', action='store_true')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    sub_to_run = np.arange(args.subjects)\n",
    "\n",
    "    pd = PrepareData(args)\n",
    "    pd.run(sub_to_run, split=True, feature=False, expand=True)\n",
    "\n",
    "    cv = CrossValidation(args)\n",
    "    seed_all(args.random_seed)\n",
    "    cv.n_fold_CV(subject=sub_to_run, fold=10, reproduce=args.reproduce)  # To do leave one trial out please set fold=40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
